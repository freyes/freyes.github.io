<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>TTY.cl</title><link href="http://tty.cl/" rel="alternate"></link><link href="http://tty.cl//feeds/articles.atom.xml" rel="self"></link><id>http://tty.cl/</id><updated>2016-08-14T00:00:00-04:00</updated><entry><title>Lynx: accept cookies always</title><link href="http://tty.cl/lynx-accept-cookies-always.html" rel="alternate"></link><published>2016-08-14T00:00:00-04:00</published><author><name>Felipe Reyes</name></author><id>tag:tty.cl,2016-08-14:lynx-accept-cookies-always.html</id><summary type="html">&lt;p&gt;From time to time I need to use &lt;a href="https://packages.ubuntu.com/lynx"&gt;lynx&lt;/a&gt; (or
any other text based browser like &lt;a href="https://packages.ubuntu.com/links"&gt;links&lt;/a&gt;),
for some reason my fingers usually type &lt;code&gt;lynx&lt;/code&gt;, but having to accept cookies
every time a new domain tries to send it to me it's annoying, so here is how
you configure it to always accept them.&lt;/p&gt;
&lt;p&gt;Add this to your &lt;code&gt;~/.bashrc&lt;/code&gt; file:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;LYNX_CFG=~/.lynx.cfg
export LYNX_CFG
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then in &lt;code&gt;~/.lynx.cfg&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;INCLUDE:/etc/lynx-cur/lynx.cfg
FORCE_SSL_COOKIES_SECURE:TRUE
SET_COOKIES:TRUE
ACCEPT_ALL_COOKIES:TRUE
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And voila!&lt;/p&gt;</summary></entry><entry><title>Multiple Local Environments with Juju</title><link href="http://tty.cl/multiple-local-environments-with-juju.html" rel="alternate"></link><published>2015-01-23T00:00:00-03:00</published><author><name>Felipe Reyes</name></author><id>tag:tty.cl,2015-01-23:multiple-local-environments-with-juju.html</id><summary type="html">&lt;p&gt;&lt;img alt="juju man" src="/images/JuJu-man.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://juju.ubuntu.com/"&gt;Juju&lt;/a&gt; has the ability to use lxc or kvm to deploy
services, this is done by the
&lt;a href="https://juju.ubuntu.com/docs/config-local.html"&gt;local provider&lt;/a&gt;, but
sometimes during development you may want to have one environment up-n-running
all the time for testing and you may need another one to run
&lt;a href="https://juju.ubuntu.com/docs/tools-amulet.html"&gt;amulet&lt;/a&gt; tests, well at the
beginning this wasn't obvious to me that this could be achieved, but then I
found how to do it :)&lt;/p&gt;
&lt;p&gt;Here is how you can have two different environments:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;environments&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;local&lt;/span&gt;
    &lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;series&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;trusty&lt;/span&gt;
    &lt;span class="n"&gt;lxc&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;clone&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
    &lt;span class="n"&gt;container&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;kvm&lt;/span&gt;
    &lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;bridge&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;br0&lt;/span&gt;
  &lt;span class="n"&gt;lxc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;local&lt;/span&gt;
    &lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;series&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;trusty&lt;/span&gt;
    &lt;span class="n"&gt;lxc&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;clone&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
    &lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;bridge&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;lxcbr0&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;37018&lt;/span&gt;
    &lt;span class="n"&gt;api&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;17071&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That is the relevant portion of my &lt;code&gt;~/.juju/environments.yaml&lt;/code&gt;, I use one environment with &lt;code&gt;kvm&lt;/code&gt; and the other one with &lt;code&gt;lxc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you're curious, the trick is to change the &lt;code&gt;state-port&lt;/code&gt; and &lt;code&gt;api-port&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I hope this helps you.&lt;/p&gt;</summary><category term="juju"></category></entry><entry><title>Deploy a Python WSGI app with a Celery worker in Heroku</title><link href="http://tty.cl/deploy-a-python-wsgi-app-with-a-celery-worker-in-heroku.html" rel="alternate"></link><published>2014-02-24T00:00:00-03:00</published><author><name>Felipe Reyes</name></author><id>tag:tty.cl,2014-02-24:deploy-a-python-wsgi-app-with-a-celery-worker-in-heroku.html</id><summary type="html">&lt;p&gt;This article explains how to deploy a WSGI python web app + a
&lt;a href="http://www.celeryproject.org"&gt;celery&lt;/a&gt; worker.&lt;/p&gt;
&lt;p&gt;A recommended reading before moving forward with Heroku is
&lt;a href="https://devcenter.heroku.com/articles/process-model"&gt;The Process Model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Jimsy" src="/images/jimsy.png" /&gt;&lt;/p&gt;
&lt;h1&gt;The Application&lt;/h1&gt;
&lt;p&gt;The application that we are going to deploy to heroku has the following components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WSGI App, it can be a &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; or
  &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; application, the important part is that you
  provide a WSGI app as entry point.&lt;/li&gt;
&lt;li&gt;Celery, we will be using a Celery worker to run background tasks, for
  example image resizing.&lt;/li&gt;
&lt;li&gt;Database, well ... you know, we usually want to save data permanently.&lt;/li&gt;
&lt;li&gt;RabbitMQ as message broker.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;The &lt;code&gt;Procfile&lt;/code&gt;!&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;Procfile&lt;/code&gt; let the developer declare the commands each dyno has to run,
there are several process' types:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Process Type&lt;/th&gt;
&lt;th&gt;Command Example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;web&lt;/td&gt;
&lt;td&gt;gunicorn app.wsgi -b 0.0.0.0:$PORT --debug&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;worker&lt;/td&gt;
&lt;td&gt;celery -A tasks worker --loglevel=info --concurrency=1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://devcenter.heroku.com/articles/scheduled-jobs-custom-clock-processes"&gt;clock&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;python foo.py&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This file is the key part to instruct Heroku what to run, for the WSGI app
we'll use a &lt;code&gt;web&lt;/code&gt; process and to run the celery worker daemon we use a
&lt;code&gt;worker&lt;/code&gt; process. Each of these processes will scale independently according
to your configuration (see
&lt;a href="https://devcenter.heroku.com/articles/scaling"&gt;Scaling Your Dyno Formation&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For our application we are going to use the following &lt;code&gt;Procfile&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
web: gunicorn app.wsgi -b 0.0.0.0:$PORT --debug
worker: celery -A app.tasks worker --loglevel=info --concurrency=1
&lt;/pre&gt;

&lt;h2&gt;Testing your &lt;code&gt;Procfile&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;One of the nice things about the &lt;code&gt;Procfile&lt;/code&gt; is that can be interpreted by
&lt;a href="http://theforeman.org/"&gt;Foreman&lt;/a&gt;, so you can test your configuration running
the following command:&lt;/p&gt;
&lt;pre&gt;
$ foreman start
17:43:11 web.1    | started with pid 31923
17:43:11 worker.1 | started with pid 31926
17:43:12 web.1    | 2014-02-19 17:43:12 [31925] [INFO] Starting gunicorn 18.0
17:43:12 web.1    | 2014-02-19 17:43:12 [31925] [INFO] Listening at: http://0.0.0.0:5000 (31925)
17:43:12 web.1    | 2014-02-19 17:43:12 [31925] [INFO] Using worker: sync
17:43:12 web.1    | 2014-02-19 17:43:12 [31938] [INFO] Booting worker with pid: 31938
17:43:14 worker.1 | [2014-02-19 17:43:14,119: WARNING/MainProcess] /home/freyes/.virtualenvs/django-todo/local/lib/python2.7/site-packages/celery/apps/worker.py:161: CDeprecationWarning: 
17:43:14 worker.1 | Starting from version 3.2 Celery will refuse to accept pickle by default.
17:43:14 worker.1 | 
17:43:14 worker.1 | The pickle serializer is a security concern as it may give attackers
17:43:14 worker.1 | the ability to execute any command.  It's important to secure
17:43:14 worker.1 | your broker from unauthorized access when using pickle, so we think
17:43:14 worker.1 | that enabling pickle should require a deliberate action and not be
17:43:14 worker.1 | the default choice.
17:43:14 worker.1 | 
17:43:14 worker.1 | If you depend on pickle then you should set a setting to disable this
17:43:14 worker.1 | warning and to be sure that everything will continue working
17:43:14 worker.1 | when you upgrade to Celery 3.2::
17:43:14 worker.1 | 
17:43:14 worker.1 |     CELERY_ACCEPT_CONTENT = ['pickle', 'json', 'msgpack', 'yaml']
17:43:14 worker.1 | 
17:43:14 worker.1 | You must only enable the serializers that you will actually use.
17:43:14 worker.1 | 
17:43:14 worker.1 | 
17:43:14 worker.1 |   warnings.warn(CDeprecationWarning(W_PICKLE_DEPRECATED))
17:43:15 web.1    | 2014-02-19 17:43:15 [31925] [INFO] Handling signal: winch
17:43:15 web.1    | 2014-02-19 17:43:15 [31925] [INFO] SIGWINCH ignored. Not daemonized
17:43:16 worker.1 | [2014-02-19 17:43:16,683: INFO/MainProcess] Connected to amqp://guest@127.0.0.1:5672//
17:43:17 worker.1 | [2014-02-19 17:43:17,323: INFO/MainProcess] mingle: searching for neighbors
17:43:19 worker.1 | [2014-02-19 17:43:19,151: INFO/MainProcess] mingle: all alone
17:43:19 worker.1 | [2014-02-19 17:43:19,750: WARNING/MainProcess] celery@tiefighter ready.
&lt;/pre&gt;

&lt;p&gt;If &lt;code&gt;foreman start&lt;/code&gt; works, then your &lt;code&gt;Procfile&lt;/code&gt; is OK.&lt;/p&gt;
&lt;h1&gt;Create the app&lt;/h1&gt;
&lt;p&gt;Once you have configured the &lt;code&gt;Profile&lt;/code&gt; we'll create an application in Heroku
(remember to install &lt;a href="https://toolbelt.heroku.com/"&gt;heroku-toolbelt&lt;/a&gt;) running
&lt;code&gt;heroku create&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Example output:&lt;/p&gt;
&lt;pre&gt;
$ heroku create
Creating murmuring-ravine-4093... done, stack is cedar
http://murmuring-ravine-4093.herokuapp.com/ | git@heroku.com:murmuring-ravine-4093.git
&lt;/pre&gt;

&lt;p&gt;This command creates a new heroku app and it adds a new remote to push your code.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;.git/config&lt;/code&gt; example:&lt;/p&gt;
&lt;pre&gt;
[remote "heroku"]
    url = git@heroku.com:desolate-fortress-2758.git
    fetch = +refs/heads/*:refs/remotes/heroku/*
&lt;/pre&gt;

&lt;h1&gt;Adding a Database&lt;/h1&gt;
&lt;p&gt;Heroku provides databases via addons, there are several providers, but for
this article we are going to use
&lt;a href="https://addons.heroku.com/heroku-postgresql"&gt;heroku-postgres&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To add it to the recently created application run &lt;code&gt;heroku addons:add
heroku-postgresql&lt;/code&gt;. Here is an example output:&lt;/p&gt;
&lt;pre&gt;
$ heroku addons:add heroku-postgresql
Adding heroku-postgresql on murmuring-ravine-4093... done, v3 (free)
Attached as HEROKU_POSTGRESQL_YELLOW_URL
Database has been created and is available
 ! This database is empty. If upgrading, you can transfer
 ! data from another database with pgbackups:restore.
Use `heroku addons:docs heroku-postgresql` to view documentation.
&lt;/pre&gt;

&lt;h1&gt;Adding RabbitMQ&lt;/h1&gt;
&lt;p&gt;We are using RabbitMQ as message broker for Celery, for this I choose to use
&lt;a href="https://addons.heroku.com/cloudamqp"&gt;CloudAMQP&lt;/a&gt;, to add it to your app run
&lt;code&gt;heroku addons:add cloudamqp&lt;/code&gt;. Here is an example output:&lt;/p&gt;
&lt;pre&gt;
$ heroku addons:add cloudamqp
Adding cloudamqp on murmuring-ravine-4093... done, v4 (free)
Use `heroku addons:docs cloudamqp` to view documentation.
&lt;/pre&gt;

&lt;h1&gt;Adjusting Settings&lt;/h1&gt;
&lt;p&gt;Heroku passes to your app environment variables with the configuration, this a common practice in the PaaS ecosystem, so you need to modify your app to read config values from it.&lt;/p&gt;
&lt;p&gt;Here are examples to setup Celery and Django:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;dj_database_url&lt;/span&gt;

&lt;span class="n"&gt;DEFAULT_AMQP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;amqp://guest:guest@localhost//&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;DEFAULT_DB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;postgres://localhost&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;db_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;DATABASE_URL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DEFAULT_DB&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Django settings&lt;/span&gt;
&lt;span class="n"&gt;DATABASES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;default&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;dj_database_url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;DEFAULT_DB&lt;/span&gt;&lt;span class="p"&gt;)}&lt;/span&gt;

&lt;span class="c1"&gt;# Celery app configuration&lt;/span&gt;
&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tasks&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;backend&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;db_url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;postgres://&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;db+postgresql://&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
             &lt;span class="n"&gt;broker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;CLOUDAMQP_URL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DEFAULT_AMQP&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BROKER_POOL_LIMIT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Launch the app!&lt;/h1&gt;
&lt;p&gt;Now we have everything configured, it's time to launch push our code and let Heroku do the magic running &lt;code&gt;git push heroku master&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;
$ git push heroku master 
Initializing repository, done.
Counting objects: 365, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (148/148), done.
Writing objects: 100% (365/365), 39.08 KiB | 0 bytes/s, done.
Total 365 (delta 206), reused 319 (delta 185)

-----&gt; Python app detected
-----&gt; No runtime.txt provided; assuming python-2.7.6.
-----&gt; Preparing Python runtime (python-2.7.6)
-----&gt; Installing Setuptools (2.1)
-----&gt; Installing Pip (1.5.2)
-----&gt; Installing dependencies using Pip (1.5.2)
       Downloading/unpacking Django==1.5.5 (from -r requirements.txt (line 1))
         Running setup.py (path:/tmp/pip_build_u26118/Django/setup.py) egg_info for package Django

       Downloading/unpacking dj-database-url==0.2.1 (from -r requirements.txt (line 2))
         Downloading dj-database-url-0.2.1.tar.gz
         Running setup.py (path:/tmp/pip_build_u26118/dj-database-url/setup.py) egg_info for package dj-database-url

       Downloading/unpacking django-extensions==0.9 (from -r requirements.txt (line 3))
         Running setup.py (path:/tmp/pip_build_u26118/django-extensions/setup.py) egg_info for package django-extensions
[...SNIP...]
         Running setup.py install for pytz

           warning: no files found matching '*.pot' under directory 'pytz'
         Running setup.py install for billiard
           building '_billiard' extension
           gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DHAVE_SEM_OPEN=1 -DHAVE_FD_TRANSFER=1 -DHAVE_SEM_TIMEDWAIT=1 -IModules/_billiard -I/app/.heroku/python/include/python2.7 -c Modules/_billiard/multiprocessing.c -o build/temp.linux-x86_64-2.7/Modules/_billiard/multiprocessing.o
           gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DHAVE_SEM_OPEN=1 -DHAVE_FD_TRANSFER=1 -DHAVE_SEM_TIMEDWAIT=1 -IModules/_billiard -I/app/.heroku/python/include/python2.7 -c Modules/_billiard/socket_connection.c -o build/temp.linux-x86_64-2.7/Modules/_billiard/socket_connection.o
           gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DHAVE_SEM_OPEN=1 -DHAVE_FD_TRANSFER=1 -DHAVE_SEM_TIMEDWAIT=1 -IModules/_billiard -I/app/.heroku/python/include/python2.7 -c Modules/_billiard/semaphore.c -o build/temp.linux-x86_64-2.7/Modules/_billiard/semaphore.o
           gcc -pthread -shared build/temp.linux-x86_64-2.7/Modules/_billiard/multiprocessing.o build/temp.linux-x86_64-2.7/Modules/_billiard/socket_connection.o build/temp.linux-x86_64-2.7/Modules/_billiard/semaphore.o -lrt -o build/lib.linux-x86_64-2.7/_billiard.so

           warning: no files found matching '*.py' under directory 'Lib'
         Running setup.py install for anyjson

       Successfully installed Django dj-database-url django-extensions django-respite django-widget-tweaks gunicorn ipdb ipython psycopg2 readline dj-static static Celery SQLAlchemy pystache kombu pytz billiard amqp anyjson
       Cleaning up...
-----&gt; Collecting static files
       /app/.heroku/python/lib/python2.7/site-packages/django/conf/urls/defaults.py:3: DeprecationWarning: django.conf.urls.defaults is deprecated; use django.conf.urls instead
       0 static files copied.

-----&gt; Discovering process types
       Procfile declares types -&gt; web, worker

-----&gt; Compressing... done, 44.2MB
-----&gt; Launching... done, v6
       http://murmuring-ravine-4093.herokuapp.com deployed to Heroku

To git@heroku.com:murmuring-ravine-4093.git
 * [new branch]      master -&gt; master
 &lt;/pre&gt;

&lt;h1&gt;Initialize the Database&lt;/h1&gt;
&lt;p&gt;We have our app running ... but the database wasn't initialized. We are using
Django in this example and we are going to run &lt;code&gt;python manage.py syncdb
--noinput&lt;/code&gt;, but for other frameworks you just replace the command with the
one you use to initialize/bootstrap the database.&lt;/p&gt;
&lt;pre&gt;
$ heroku run python manage.py syncdb --noinput
Running `python manage.py syncdb --noinput` attached to terminal... up, run.5257
/app/.heroku/python/lib/python2.7/site-packages/django/conf/urls/defaults.py:3: DeprecationWarning: django.conf.urls.defaults is deprecated; use django.conf.urls instead
  DeprecationWarning)

Creating tables ...
Creating table auth_permission
Creating table auth_group_permissions
Creating table auth_group
Creating table auth_user_groups
Creating table auth_user_user_permissions
Creating table auth_user
Creating table django_content_type
Creating table django_session
Creating table django_site
Creating table tasks_task
Installing custom SQL ...
Installing indexes ...
Installed 0 object(s) from 0 fixture(s)
&lt;/pre&gt;

&lt;p&gt;And now we are ready to take a look to our app running &lt;code&gt;heroku open&lt;/code&gt; which will open your browser pointing to your app.&lt;/p&gt;
&lt;h1&gt;What now?&lt;/h1&gt;
&lt;p&gt;We have the app running and a celery worker, now it's moment to assign a
decent domain and other minor settings, heroku provides an option called
&lt;a href="https://devcenter.heroku.com/articles/production-check"&gt;Production Check&lt;/a&gt;,
you should use it before going live with your site.&lt;/p&gt;</summary><category term="development"></category></entry><entry><title>Deploying a Python WSGI app with Vagrant and Puppet</title><link href="http://tty.cl/deploying-a-python-wsgi-app-with-vagrant-and-puppet.html" rel="alternate"></link><published>2014-01-22T00:00:00-03:00</published><author><name>Felipe Reyes</name></author><id>tag:tty.cl,2014-01-22:deploying-a-python-wsgi-app-with-vagrant-and-puppet.html</id><summary type="html">&lt;p&gt;These days the tendency among software companies is to have everything under
version control systems (i.e. &lt;a href="http://git-scm.com/"&gt;Git&lt;/a&gt;,
&lt;a href="http://mercurial.selenic.com/"&gt;Mercurial&lt;/a&gt;), all these is part of two software
development strategies: &lt;a href="http://en.wikipedia.org/wiki/Continuous_integration"&gt;continuous integration&lt;/a&gt;
and &lt;a href="http://en.wikipedia.org/wiki/Continuous_delivery"&gt;continuous delivery&lt;/a&gt;.
To read more about them I recommend you to read &lt;a href="http://www.amazon.com/Continuous-Integration-Improving-Software-Reducing/dp/0321336380/ref=sr_1_1?ie=UTF8&amp;amp;qid=1390443569&amp;amp;sr=8-1&amp;amp;keywords=continuous+integration"&gt;"Continuous Integration: Improving Software Quality and Reducing Risk"&lt;/a&gt;
and &lt;a href="http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912/ref=sr_1_3?ie=UTF8&amp;amp;qid=1390443569&amp;amp;sr=8-3&amp;amp;keywords=continuous+integration"&gt;"Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation"&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So I took &lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt; to provision the machines that
will run my &lt;a href="https://github.com/freyes/flask-hello-world"&gt;example webapp&lt;/a&gt;, and
&lt;a href="http://puppetlabs.com"&gt;Puppet&lt;/a&gt; will take care of configuring my system.&lt;/p&gt;
&lt;p&gt;My recipes are in continuous development, so you should refer to the git
repositories for the latest information about how they work.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/freyes/vagrant-puppet-example"&gt;Vagrant and Puppet recipes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/freyes/flask-hello-world"&gt;Flask hello world&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="python"></category><category term="vagrant"></category><category term="puppet"></category><category term="wsgi"></category></entry><entry><title>MySQL and the Key Cache Buffer</title><link href="http://tty.cl/mysql-and-the-key-cache-buffer.html" rel="alternate"></link><published>2011-12-18T00:00:00-03:00</published><author><name>Jonathan Gonzalez</name></author><id>tag:tty.cl,2011-12-18:mysql-and-the-key-cache-buffer.html</id><summary type="html">&lt;h1&gt;Why did I learn?&lt;/h1&gt;
&lt;p&gt;It's always important to recognize why this happened, well, here in my
work a few weeks ago I set up a &lt;a href="http://code.google.com/p/mysql-cacti-templates/"&gt;few new templates&lt;/a&gt; for our &lt;a href="http://www.cacti.net/"&gt;Cacti&lt;/a&gt;, among
many useful templates it comes with some very handy templates for
&lt;a href="http://www.mysql.com"&gt;MySQL&lt;/a&gt;, it comes with a pretty useful template called 'MyISAM Key Cache'
and we noticed that it was full!! so my boss ask me to figure out and
read about this topic and many others that aren't the main topic
of this article&lt;/p&gt;
&lt;h1&gt;Find out your current configuration&lt;/h1&gt;
&lt;p&gt;Since you may not have cacti installed you may need to know what do
you have and how it's working now.&lt;/p&gt;
&lt;p&gt;First the value of your 'key buffer size':&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
show variables like 'key%';&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will show at least, two good things that may be useful for you,
'key buffer size', yes the size of our key buffer! and
'key cache block size' useful to end our tiny article&lt;/p&gt;
&lt;p&gt;Well, now we have to know how the key buffer its used:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
show status like 'Key%';&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;All the rows returned from this command are useful! I'll use and
example of one of our servers:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mysql&amp;gt; show status like 'Key%';
+------------------------+-----------+
| Variable_name          | Value     |
+------------------------+-----------+
| Key_blocks_not_flushed | 0         |
| Key_blocks_unused      | 240934    |
| Key_blocks_used        | 97093     |
| Key_read_requests      | 211305615 |
| Key_reads              | 321341    |
| Key_write_requests     | 9268658   |
| Key_writes             | 397761    |
+------------------------+-----------+
7 rows in set (0.00 sec)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We now have all the data we need to evaluate  our current situation.&lt;/p&gt;
&lt;h1&gt;Use the collected data&lt;/h1&gt;
&lt;p&gt;We will suppose that the value of 'key buffer size' it's '402653184'
the first things we need to know it's that this value it's in bytes so
if you prefer to manage it in megabytes you need to do the
transformation:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;(402653184/1024)/1024 = 384&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We have a Key cache buffer of 384MB which looks like a lot of space,
but how much of that space it's currently used? well, you will have to
do simple calculation:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;key_buffer_usage = ( Key_blocks_unused * key_cache_block_size ) / key_buffer_size ) * 100&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So with our collected that we will suppose that the value of
'key cache block size' it's 1024 which it's the default value.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;( (240934 * 1024) / 402653184 ) * 100 = 61.2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So, we have about 61.2 percent of our buffer used, ok this seems to be
right, but there's another data we may find useful! look this extract
from the &lt;a href="http://dev.mysql.com/doc/"&gt;MySQL Documentation&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;"The Key reads/Key read requests ratio should normally be less than
0.01."&lt;/p&gt;
&lt;p&gt;Ok, what the heck this guys mean by that? Well, let's try our maths to
calculate our ratio!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;key_reads_ratio =  ( Key_reads / Key_read_requests ) * 100&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And with our data it will be something like:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;( 321341 / 211305615 ) * 100 = 0.152074046&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So, we have a ratio of about 0.15, this doesn't seem a lot to me, but
according to the documentation it's a lot, well, according to the
maths with less key_reads(keys passed to the 'key buffer') and lots of
'key read requests' our 'key reads ratio' should be lower.&lt;/p&gt;
&lt;h1&gt;Test and not necessarily a fix!&lt;/h1&gt;
&lt;p&gt;OK, so you may want to take a look inside your my.cnf, but come on you
can't restart your database right?&lt;/p&gt;
&lt;p&gt;Well, if you access your database as 'root' user you can start to
throw a few commands to set these values!&lt;/p&gt;
&lt;p&gt;Let's say we want to set up our key buffer, we should do this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
set global key_buffer_size=512*1024*1024;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Thus, we will set our key_buffer to 512M and our system will have a
lot of more key cached and our ratio will go down! awesome right? but
wait, there's a tricks an some cautions you may want to take!&lt;/p&gt;
&lt;p&gt;First, if your database it's on production, when you set the value
your cached keys will be lost, thus, the load of your system will
increase significantly so, do this carefully!&lt;/p&gt;
&lt;p&gt;Second, you have to wait a lot to calculate, at first, your
key_reads_ratio will not reflect your situation so wait a bit, well,
if you have a lot of users for your database and queries obviously you
will have to wait less.&lt;/p&gt;
&lt;h1&gt;Other Stuffs? no, just the end&lt;/h1&gt;
&lt;p&gt;Well, I'll still working with some &lt;a href="http://www.mysql.com]"&gt;MySQL&lt;/a&gt; optimization things, so, I'll
probably upload more things related to this kind of optimizations.&lt;/p&gt;
&lt;p&gt;Remember, creating graphs of your system will always help you to
diagnostic your system =)&lt;/p&gt;</summary><category term="mysql"></category><category term="tuning"></category><category term="database"></category><category term="cache"></category></entry></feed>